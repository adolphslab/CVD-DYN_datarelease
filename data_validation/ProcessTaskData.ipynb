{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks completed per wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "parent_dir = Path().resolve().parents[0]\n",
    "data_dir = os.path.join(parent_dir, 'data', 'task_data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longString(ser):\n",
    "    strs=[]\n",
    "    strCtr=1\n",
    "    lval=ser.iloc[0]\n",
    "    for ind in range(1,ser.shape[0]):\n",
    "        if ser.iloc[ind]==lval:\n",
    "            strCtr+=1\n",
    "        else:\n",
    "            strs.append(strCtr)\n",
    "            strCtr=1\n",
    "            lval=ser.iloc[ind]\n",
    "\n",
    "    if len(strs)==0:\n",
    "        strs.append(strCtr)\n",
    "        \n",
    "    maxLongStr=np.max(strs)\n",
    "    meanStrLength=np.mean(strs)\n",
    "    countLongStr=np.sum(np.array(strs)>5)\n",
    "    \n",
    "    out={'maxLongStr':maxLongStr,\n",
    "           'meanLongString':np.round(meanStrLength,2),\n",
    "           'countLongStr':countLongStr,\n",
    "        }\n",
    "           \n",
    "    \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSP TASK\n",
    "consp = pd.read_csv(os.path.join(data_dir, 'CONSP_P_CVDID.csv'))\n",
    "consp_qual = pd.DataFrame()\n",
    "consp.CVDID = consp.CVDID.astype('float')\n",
    "\n",
    "for cvdid in consp.CVDID.unique():\n",
    "    for w in  consp.loc[consp.CVDID ==cvdid, 'cvd_consp_wave'].unique():\n",
    "        \n",
    "        tmp_dat = consp.loc[(consp.CVDID == cvdid)&(consp.cvd_consp_wave == w),:].copy()\n",
    "        tmp_dat = tmp_dat.dropna(subset='cvd_consp_key_press').reset_index(drop = True)\n",
    "                    \n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # response button press variance \n",
    "        consp_long_string = longString(tmp_dat.cvd_consp_key_press)\n",
    "        sub_dict['cvd_consp_meanLongString'] = consp_long_string['maxLongStr']        \n",
    "                \n",
    "        # reaction time\n",
    "        sub_dict['cvd_consp_rt_pctlt_300']=np.sum(tmp_dat.cvd_consp_rt<300)/tmp_dat.shape[0]\n",
    "        \n",
    "        sub_dict['cvd_consp_administered'] = True\n",
    "        consp_qual = pd.concat([consp_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "\n",
    "del consp\n",
    "consp_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRUST TASK\n",
    "tr1 = pd.read_csv(os.path.join(data_dir, 'TR1_P_CVDID.csv'))\n",
    "tr1_qual = pd.DataFrame()\n",
    "tr1.CVDID = tr1.CVDID.astype('float')\n",
    "\n",
    "for cvdid in tr1.CVDID.unique():\n",
    "    for w in  tr1.loc[tr1.CVDID ==cvdid, 'tr_1s_wave'].unique():\n",
    "        \n",
    "        tmp_dat = tr1.loc[(tr1.CVDID == cvdid)&(tr1.tr_1s_wave == w),:].copy().reset_index(drop = True)\n",
    "                    \n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # response button press variance \n",
    "        tr1_long_string = longString(tmp_dat.tr_1s_key_press)\n",
    "        sub_dict['tr_1s_meanLongString'] = tr1_long_string['maxLongStr']        \n",
    "        if tmp_dat.tr_1s_key_press.var() == 0:\n",
    "             sub_dict['tr_1s_noVar'] = 1\n",
    "        else:\n",
    "             sub_dict['tr_1s_noVar'] = 0  \n",
    "                \n",
    "        # reaction time/ task duration\n",
    "        sub_dict['tr_1s_totalTime'] = tmp_dat.tr_1s_totalTime[0]\n",
    "        sub_dict['tr_1s_medianRT'] = tmp_dat.tr_1s_rt.median()\n",
    "        sub_dict['tr_1s_rt_pctlt_300']=np.sum(tmp_dat.tr_1s_rt<300)/tmp_dat.shape[0]\n",
    "        \n",
    "        sub_dict['tr_1s_administered'] = True\n",
    "        tr1_qual = pd.concat([tr1_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "        \n",
    "del tr1\n",
    "tr1_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iat = pd.read_csv(os.path.join(data_dir, 'IAT_P_CVDID.csv'))\n",
    "iat_qual = pd.DataFrame()\n",
    "iat.CVDID = iat.CVDID.astype('float')\n",
    "\n",
    "\n",
    "for cvdid in iat.CVDID.unique():\n",
    "    for w in  iat.loc[iat.CVDID ==cvdid, 'iat_wave'].unique():\n",
    "        \n",
    "        tmp_dat = iat.loc[(iat.CVDID == cvdid)&(iat.iat_wave == w),:].copy().reset_index(drop = True)\n",
    "        \n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # reaction time/ task duration\n",
    "        sub_dict['iat_include'] = (~np.isnan(tmp_dat.iat_iatd[0])).astype(int)\n",
    "        sub_dict['iat_totalTime'] = tmp_dat.iat_totalTime[0]\n",
    "        sub_dict['iat_administered'] = True\n",
    "        iat_qual = pd.concat([iat_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "\n",
    "del iat\n",
    "iat_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = pd.read_csv(os.path.join(data_dir, 'AMP_P_CVDID.csv'))\n",
    "amp_qual = pd.DataFrame()\n",
    "amp.CVDID = amp.CVDID.astype('float')\n",
    "\n",
    "\n",
    "for cvdid in amp.CVDID.unique():\n",
    "    for w in  amp.loc[amp.CVDID ==cvdid, 'amp_wave'].unique():\n",
    "        tmp_dat = amp.loc[(amp.CVDID == cvdid)&(amp.amp_wave == w),:].copy().reset_index(drop = True)\n",
    "\n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # response button press variance \n",
    "        amp_long_string = longString(tmp_dat.amp_key_press)\n",
    "        sub_dict['amp_meanLongString'] = amp_long_string['maxLongStr']        \n",
    "\n",
    "        # reaction time/ task duration\n",
    "        sub_dict['amp_totalTime'] = tmp_dat.amp_totalTime[0]\n",
    "        sub_dict['amp_medianRT'] = tmp_dat.amp_rt.median()\n",
    "        sub_dict['amp_pct_bad_rts']= 1 - tmp_dat.amp_prct_usable_trials[0]\n",
    "        \n",
    "        sub_dict['amp_administered'] = True\n",
    "        amp_qual = pd.concat([amp_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "\n",
    "del amp\n",
    "amp_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altt = pd.read_csv(os.path.join(data_dir, 'ATT_P_CVDID.csv'))\n",
    "altt_qual = pd.DataFrame()\n",
    "altt.CVDID = altt.CVDID.astype('float')\n",
    "\n",
    "for cvdid in altt.CVDID.unique():\n",
    "    for w in  altt.loc[altt.CVDID ==cvdid, 'cvd_altt_wave'].unique():\n",
    "        tmp_dat = altt.loc[(altt.CVDID == cvdid)&(altt.cvd_altt_wave == w),:].copy().reset_index(drop = True)\n",
    "\n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # response button press variance \n",
    "        altt_long_string = longString(tmp_dat.cvd_altt_key_press)\n",
    "        sub_dict['altt_meanLongString'] = altt_long_string['maxLongStr']        \n",
    "\n",
    "        # reaction time/ task duration\n",
    "        sub_dict['altt_totalTime'] = tmp_dat.cvd_altt_totalTime[0]\n",
    "        sub_dict['altt_medianRT'] = tmp_dat.cvd_altt_rt.median()\n",
    "        sub_dict['altt_rt_pctlt_300']=np.sum(tmp_dat.cvd_altt_rt<300)/tmp_dat.shape[0]\n",
    "\n",
    "        \n",
    "        sub_dict['altt_administered'] = True\n",
    "        altt_qual = pd.concat([altt_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "        \n",
    "\n",
    "del altt\n",
    "altt_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biat_raw = pd.read_csv(os.path.join(data_dir, 'BIAT_P_CVDID.csv'))\n",
    "biat_summary = pd.read_csv(os.path.join(data_dir, 'BIAT_summary_P_CVDID.csv'))\n",
    "biat_qual = pd.DataFrame()\n",
    "biat_raw.CVDID = biat_raw.CVDID.astype('float')\n",
    "biat_summary.CVDID = biat_summary.CVDID.astype('float')\n",
    "\n",
    "for cvdid in biat_raw.CVDID.unique():\n",
    "    for w in  biat_raw.loc[biat_raw.CVDID ==cvdid, 'biat_wave'].unique():\n",
    "        tmp_dat = biat_raw.loc[(biat_raw.CVDID == cvdid)&(biat_raw.biat_wave == w),:].copy().reset_index(drop = True)\n",
    "\n",
    "        sub_dict = {}\n",
    "        sub_dict['CVDID'] = cvdid\n",
    "        sub_dict['wave'] = w\n",
    "        \n",
    "        # reaction time/ task duration\n",
    "        sub_dict['biat_totalTime'] = tmp_dat.biat_totalTime[0]\n",
    "        sub_dict['biat_include'] =biat_summary.loc[(biat_summary.CVDID ==cvdid) & (biat_summary.biat_wave ==w), 'biat_include'].values[0]\n",
    "        sub_dict['biat_administered'] = True\n",
    "        biat_qual = pd.concat([biat_qual,pd.DataFrame.from_dict(sub_dict, orient = 'index').T])\n",
    "        \n",
    "del biat_raw, biat_summary\n",
    "\n",
    "biat_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgg = pd.read_csv(os.path.join(data_dir, 'PGG_P_CVDID.csv'))\n",
    "pgg['pgg_administered'] = True\n",
    "pgg = pgg.rename(columns = {'pgg_wave': 'wave'})\n",
    "pgg_qual = pgg[['CVDID', 'wave', 'pgg_administered']].copy()\n",
    "pgg_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_qual = altt_qual.merge(tr1_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)\n",
    "task_qual = task_qual.merge(amp_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)\n",
    "task_qual = task_qual.merge(iat_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)                             \n",
    "task_qual = task_qual.merge(biat_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)                             \n",
    "task_qual = task_qual.merge(consp_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)                             \n",
    "task_qual = task_qual.merge(pgg_qual, on=['CVDID','wave'], how = 'outer').reset_index(drop = True)            \n",
    "task_qual.to_csv(os.path.join(data_dir, 'task_qual.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVD-datapaper",
   "language": "python",
   "name": "cvd-datapaper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
